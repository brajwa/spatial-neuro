#           theme(legend.position="top", legend.text=element_text(size=16), legend.title = element_blank(),
#                 legend.box.margin=margin(-10,-10,-10,-10),
#                 plot.title = element_text(hjust = 0.5, size=18),
#                 plot.subtitle = element_text(hjust = 0.5, size=16),
#                 axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16),
#                 axis.title.x = element_text(size = 16), axis.title.y = element_text(size = 16),
#                 panel.background = element_rect(fill='white', colour='black'),
#                 panel.grid.major = element_line(color = "grey", linewidth=0.25, linetype=2)) +
#           xlab(expression(paste("Face Area"))) + ylab("Density")+
#           labs(title = "Comparison of face feature of original and simulated networks") )
#
# # edge angle
# den_org_e_angle = density(apply(branch.all, 1, function(x) calcAngle(x)))
# den_org_e_angle = data.frame(x=den_org_e_angle$x, y=den_org_e_angle$y)
#
# den_sim_e_angle = density(network_extra1$anglecomp)
# den_sim_e_angle = data.frame(x=den_sim_e_angle$x, y= den_sim_e_angle$y)
#
# print(ggplot() +
#           geom_line(data = den_org_e_angle, aes(x=x, y=y), color = "blue") +
#           geom_area(data = den_org_e_angle, aes(x=x, y=y), fill = "blue", alpha=0.3) +
#           geom_line(data = den_sim_e_angle, aes(x=x, y=y), color="red") +
#           geom_area(data = den_sim_e_angle, aes(x=x, y=y), fill="red", alpha=0.3) +
#
#           geom_vline(xintercept = network_extra1$anglecomp[selected_edge],color = "black") +
#
#           theme(legend.position="top", legend.text=element_text(size=16), legend.title = element_blank(),
#                 legend.box.margin=margin(-10,-10,-10,-10),
#                 plot.title = element_text(hjust = 0.5, size=18),
#                 plot.subtitle = element_text(hjust = 0.5, size=16),
#                 axis.text.x = element_text(size = 16), axis.text.y = element_text(size = 16),
#                 axis.title.x = element_text(size = 16), axis.title.y = element_text(size = 16),
#                 panel.background = element_rect(fill='white', colour='black'),
#                 panel.grid.major = element_line(color = "grey", linewidth=0.25, linetype=2)) +
#           xlab(expression(paste("Edge Angle"))) + ylab("Density")+
#           labs(title = "Comparison of edge feature of original and simulated networks")  )
edge_reject = FALSE
epsilon_f = 6e-06
epsilon_e = 0
#### prediction
org_est_1 = predict(orgKDE_face_feat_1, x=c(temp_face_area_list[face_p_index], temp_face_features$elong[face_p_index], temp_face_features$orient[face_p_index]))
org_est_2 = predict(orgKDE_face_feat_2, x=c(temp_face_node_count[face_p_index]))
temp_tri_est_1 = predict(temp_triKDE_face_feat_1, x=c(temp_face_area_list[face_p_index], temp_face_features$elong[face_p_index], temp_face_features$orient[face_p_index]))
temp_tri_est_2 = predict(temp_triKDE_face_feat_2, x=c(temp_face_node_count[face_p_index]))
# cat("\nFace est. 1 diff: ", (org_est_1 - temp_tri_est_1), "\n")
# cat("\nFace est. 2 diff: ", (org_est_2 - temp_tri_est_2), "\n")
#
# cat("Face convexity of the new face: ", temp_face_convexity_list[face_p_index], "\n")
#
# org_edge_est = predict(orgKDE_edge_feat, x=network_extra1$anglecomp[selected_edge])
# tri_edge_est = predict(temp_triKDE_edge_feat, x=network_extra1$anglecomp[selected_edge])
#
# cat("\nEdge est. diff: ", (tri_edge_est - org_edge_est), "\n")
if(temp_face_convexity_list[face_p_index] < org_face_convexity_mean){ # another option: mean(temp_face_convexity_list) < org_face_convexity_mean
#### keep the edge, no change
noChange = noChange + 1
cat("\nEdge kept [Face convexity constraint]\n")
}else{
if(length(face_index)==2){
f1 = face_index[1]
f2 = face_index[2]
if((org_est_1+epsilon_f >= temp_tri_est_1) ){
edge_reject = TRUE
}
}else if(length(face_index)==1){
f1 = face_index[1]
if((org_est_1+epsilon_f >= temp_tri_est_1) ){
edge_reject = TRUE
}
}else{
cat("\nError in face identification 1\n")
quit()
}
}
if(edge_reject){
#### remove the edge, there is a change
noChange = 0
cat("\nEdge deleted\n")
#### make necessary changes permanent
network_extra1 = temp_network_extra1
g2_degree = igraph::degree(temp_graph_obj, mode="total")
#cat("Degree of vertices after edge deletion: ", g2_degree[v1], g2_degree[v2], "\n")
print(table(g2_degree))
face_list = temp_face_list
face_area_list = temp_face_area_list
face_node_count = temp_face_node_count
triKDE_face_feat_1 = temp_triKDE_face_feat_1
triKDE_face_feat_2 = temp_triKDE_face_feat_2
triKDE_edge_feat =  temp_triKDE_edge_feat
tri_face_features = temp_face_features
}else{
#### keep the edge, no change
noChange = noChange + 1
cat("\nEdge kept [Face feature and/or edge estimation constraint]\n")
}
}else{
#### keep the edge, no change
noChange = noChange + 1
cat("\nEdge kept [Connectivity constraint]\n")
}
#### temporarily plotting each iteration
graph_obj =  make_empty_graph() %>% add_vertices(gen.ppp$n)
graph_obj = add_edges(as.undirected(graph_obj),
as.vector(t(as.matrix(network_extra1[,5:6]))))
#### Transitivity measures the probability that the adjacent vertices of a vertex are connected.
#### This is sometimes also called the clustering coefficient.
cluster_coeff_s = igraph::transitivity(graph_obj, type = "global")
cat("\nCC Sim: ", cluster_coeff_s, "\n")
#### construct and display as corresponding ppp and linnet
degs = igraph::degree(graph_obj, mode="total")
# ord = order(as.numeric(names(degs)))
# degs = degs[ord]
#### attach the degree information to the point pattern for proper visualization
marks(gen.ppp) = factor(degs)
gen.ppp$markformat = "factor"
g_o_lin = linnet(gen.ppp, edges=as.matrix(network_extra1[,5:6]))
branch.lpp_s = lpp(gen.ppp, g_o_lin )
plot(branch.lpp_s, main="Sim", pch=21, cex=1.2, bg=c("black", "red3", "green3", "orange",
"dodgerblue", "white", "maroon1",
"mediumpurple", "yellow", "cyan"))
}
}
#### compute index of the boundary edges again
bb_edges_2 = which((vertex_dist_boundary[network_extra1$ind1]==0) &
(vertex_dist_boundary[network_extra1$ind2]==0) &
((gen.ppp$x[network_extra1$ind1]==gen.ppp$x[network_extra1$ind2])|
(gen.ppp$y[network_extra1$ind1]==gen.ppp$y[network_extra1$ind2]) ) )
#### eliminate boundary-boundary edges
cat("Eliminating boundary edges\n")
after_elim_0 = eliminateEdges(gen.ppp, network_extra1, bb_edges_2)
noChange = after_elim_0[[1]]
network_extra1 = after_elim_0[[2]]
g2_degree = after_elim_0[[3]]
face_list = after_elim_0[[4]]
face_area_list = after_elim_0[[5]]
face_node_count = after_elim_0[[6]]
triKDE_face_feat_1 = after_elim_0[[7]]
triKDE_face_feat_2 = after_elim_0[[8]]
triKDE_edge_feat = after_elim_0[[9]]
tri_face_features = after_elim_0[[10]]
face_convexity_mean = after_elim_0[[11]]
#### figure out the vertex id of the corner points
c_v = c()
for (i in c(1:gen.ppp$n)) {
if(isCornerV(i, gen.ppp)){
c_v = c(c_v, i)
}
}
#### compute index of the corner edges
c_e = which(network_extra1$ind1 %in% c_v | network_extra1$ind2 %in% c_v)
#### remove corner points any edge incident on them
gen.ppp_2 = subset.ppp(gen.ppp, !((x==gen.ppp$window$xrange[1] | x==gen.ppp$window$xrange[2])
& (y==gen.ppp$window$yrange[1] | y==gen.ppp$window$yrange[2])))
#### eliminate corner edges
cat("Eliminating corner edges\n")
after_elim_1 = eliminateEdges(gen.ppp, network_extra1, c_e)
noChange = after_elim_1[[1]]
network_extra1 = after_elim_1[[2]]
g2_degree = after_elim_1[[3]]
face_list = after_elim_1[[4]]
face_area_list = after_elim_1[[5]]
face_node_count = after_elim_1[[6]]
triKDE_face_feat_1 = after_elim_1[[7]]
triKDE_face_feat_2 = after_elim_1[[8]]
triKDE_edge_feat = after_elim_1[[9]]
tri_face_features = after_elim_1[[10]]
face_convexity_mean = after_elim_1[[11]]
#### final simulated network
graph_obj =  make_empty_graph() %>% add_vertices(gen.ppp_2$n)
graph_obj = add_edges(as.undirected(graph_obj),
as.vector(t(as.matrix(network_extra1[,5:6]))))
#### Transitivity measures the probability that the adjacent vertices of a vertex are connected.
#### This is sometimes also called the clustering coefficient.
cluster_coeff_s = igraph::transitivity(graph_obj, type = "global")
cat("CC Sim: ", cluster_coeff_s, "\n")
#### construct and display as corresponding ppp and linnet
degs = igraph::degree(graph_obj, mode="total")
# ord = order(as.numeric(names(degs)))
# degs = degs[ord]
#### attach the degree information to the point pattern for proper visualization
marks(gen.ppp_2) = factor(degs)
gen.ppp_2$markformat = "factor"
g_o_lin = linnet(gen.ppp_2, edges=as.matrix(network_extra1[,5:6]))
branch.lpp_s = lpp(gen.ppp_2, g_o_lin )
plot(branch.lpp_s, main="Sim", pch=21, cex=1.2, bg=c("black", "red3", "green3", "orange",
"dodgerblue", "white", "maroon1",
"mediumpurple", "yellow", "cyan"))
return(list(gen.ppp_2, network_extra1))
}
generateNetworkEdges_3 <- function(gen.ppp, branch.ppp, branch_all, org_face_feature, orgKDE_face_feat_1, orgKDE_face_feat_2, orgKDE_edge_feat,
meshedness, network_density, compactness, cluster_coeff, org_max_deg,
sample_id, org_face_convexity_mean){
#### constructing the deterministic Delaunay triangulation as the initial ganglionic network
triangulation_info_list = deterministicEdges_3(gen.ppp, branch.ppp, branch.all, org_face_feature, sample_id, org_face_convexity_mean)
#### returned values
network_extra1 = triangulation_info_list[[1]]
face_list = triangulation_info_list[[2]]
face_area_list = triangulation_info_list[[3]]
face_node_count = triangulation_info_list[[4]]
triKDE_face_feat_1 = triangulation_info_list[[5]]
triKDE_face_feat_2 = triangulation_info_list[[6]]
triKDE_edge_feat = triangulation_info_list[[7]]
g2_degree = triangulation_info_list[[8]]
tri_face_features = triangulation_info_list[[9]]
#### remove edges from the initial triangulation by rejection sampling
sampled_net = rejectionSampling_3(gen.ppp, branch.ppp, branch.all, org_face_feature, network_extra1, face_list, face_area_list, face_node_count,
g2_degree, orgKDE_face_feat_1, orgKDE_face_feat_2, triKDE_face_feat_1, triKDE_face_feat_2, orgKDE_edge_feat, triKDE_edge_feat,
meshedness, network_density, compactness, cluster_coeff, org_max_deg,
sample_id, tri_face_features, org_face_convexity_mean)
gen.ppp = sampled_net[[1]]
network_extra = sampled_net[[2]]
#### create a graph from sampled triangulation
g2 = make_empty_graph() %>% add_vertices(gen.ppp$n)
g2 = add_edges(as.undirected(g2), as.vector(t(as.matrix(network_extra[,5:6]))))
#### display as corresponding ppp and linnet
g2_lin = linnet(gen.ppp, edges=as.matrix(network_extra[, 5:6]))
return(list(gen.ppp, network_extra, g2_lin))
}
####main
#### extracting parent directory information for accessing input and output location
dir = this.dir()
folder = strsplit(dir, "/")
folder = folder[[1]][length(folder[[1]])]
parent = strsplit(dir, folder)
face_folder = paste(parent, "Outputs/ENSMouse/FaceFeature/", sep="")
face_features_combined = read.csv(paste(face_folder, "FaceFeatures_3.csv", sep = ""))
#### the TIF images of the ganglionic networks are preprocessed in Fiji (ImageJ) and
#### the network information is extracted as .csv files
branch_info_folder = paste(parent, "Data/ENSMouse Branch Information (in um) v2.0/", sep="")
branch_info_files = list.files(branch_info_folder, recursive = TRUE, pattern = "\\.csv", full.names = TRUE)
i = 2 # index of the ENS network we want to work on
ens_location = strsplit(branch_info_files[i], "/")[[1]][11]
sample_id = strsplit(strsplit(branch_info_files[i], "/")[[1]][12], "\\.")[[1]][1]
cat("\n(", i, ") Location: ", ens_location, "\nSample Id: ", sample_id, "\n")
max_y = 1 # 4539.812 found by computation; right now keeping everything unscaled as the moments can not be computed otherwise
data_struct_list = constructDataStruct(sample_id, parent, branch_info_files[i], output_folder_path, max_y)
#### the returned values
branch.all = data_struct_list[[1]]
branch.ppp = data_struct_list[[2]]  # marked point pattern, degree of the points as marks
branch.lpp = data_struct_list[[3]]
g1 = data_struct_list[[4]]
hardcoreStrauss_model_param = data_struct_list[[5]]
plot(branch.lpp, main="original", pch=21, cex=1.2, bg=c("black", "red3", "green3", "orange", "dodgerblue",
"white", "maroon1", "mediumpurple"))
#### alpha, gamma, psi (meshedness, network density and compactness parameters)
N = branch.ppp$n
E = length(branch.all$x1)
A = summary(branch.ppp)$window$area
L = sum(branch.all$euclid)
meshedness = (E-N+1)/((2*N)-5)
network_density = E/((3*N)-6)
compactness = 1- ((4*A)/(L-(2*sqrt(A)))^2)
cat("Meshedness: ", meshedness, ", Network density: ", network_density, ", Compactness: ", compactness, "\n")
#### Transitivity measures the probability that the adjacent vertices of a vertex are connected.
#### This is sometimes also called the clustering coefficient.
cluster_coeff = igraph::transitivity(g1, type = "global")
cat("CC original: ", cluster_coeff, "\n")
org_max_deg = max(igraph::degree(g1))
#### filter out the face face features of the sample under consideration
#### Reminder: the face features were computed assuming additional edges were computed
#### to close the open faces at the boundary
#### similar thing should be done for the new network too (where needed).
face_feature = face_features_combined[face_features_combined$sample_id == sample_id, ]
org_face_convexity_mean = mean(face_feature$Convexity)
org_face_convexity_sd = sd(face_feature$Convexity)
cat("original avg face convexity: ", org_face_convexity_mean, "\n")
orgKDE_face_feat_1 = kde(as.matrix(data.frame(face_feature$Area_SL, face_feature$Elong., face_feature$Orient.)))
orgKDE_face_feat_2 = kde(as.matrix(data.frame(face_feature$Node_Count)),
h=density(face_feature$Node_Count)$bw)
orgKDE_edge_feat = kde(as.matrix(data.frame(apply(branch.all, 1, function(x) calcAngle(x)),
branch.all$euclid)))
####At this point, new point pattern will be simulated.
####For now we are generating networks on the original point pattern.
####branch.ppp will be replaced by some new ppp object
gen.ppp = unmark(branch.ppp)
gen_corner.ppp = ppp(x=c(gen.ppp$window$xrange[1], gen.ppp$window$xrange[2], gen.ppp$window$xrange[2], gen.ppp$window$xrange[1]),
y=c(gen.ppp$window$yrange[2], gen.ppp$window$yrange[2], gen.ppp$window$yrange[1], gen.ppp$window$yrange[1]),
window = gen.ppp$window)
gen.ppp = superimpose(gen.ppp, gen_corner.ppp)
#### call the network generation functions
network_info_list = generateNetworkEdges_3(gen.ppp, branch.ppp, branch_all, face_feature, orgKDE_face_feat_1, orgKDE_face_feat_2, orgKDE_edge_feat,
meshedness, network_density, compactness, cluster_coeff, org_max_deg,
sample_id, org_face_convexity_mean)
#### loading required libraries (there might be more libraries loaded than required)
load_lib = c("deldir", "spatstat", "magrittr", "dplyr", "igraph", "scales", "httr", "tidyverse", "ggnetwork", "ggplot2", "poweRlaw",
"imager", "viridis", "plotrix", "openxlsx", "tidyr", "spdep", "maptools", "tmap", "OpenImageR", "dismo", "lctools",
"officer", "rvg", "truncnorm", "emdist", "ks", "rlist", "readxl", "OneR", "MASS", "RColorBrewer", "this.path",
"causaloptim", "RBGL", "svglite", "ggrepel", "devtools", "geosphere", "collections",
"readtext")
install_lib = load_lib[!load_lib %in% installed.packages()]
for(lib in install_lib) install.packages(lib, dependencies=TRUE)
sapply(load_lib, require, character=TRUE)
text_data = readtext("C:/Users/sanja/Documents/GitHub/Salmonella/Data/SAL_TimeLaps_Robot2/SAL_TimeLaps_Robot2.txt")
View(text_data)
text_data
readtext("C:/Users/sanja/Documents/GitHub/Salmonella/Data/SAL_TimeLaps_Robot2/SAL_TimeLaps_Robot2.txt")
#### loading required libraries (there might be more libraries loaded than required)
load_lib = c("deldir", "spatstat", "magrittr", "dplyr", "igraph", "scales", "httr", "tidyverse", "ggnetwork", "ggplot2", "poweRlaw",
"imager", "viridis", "plotrix", "openxlsx", "tidyr", "spdep", "maptools", "tmap", "OpenImageR", "dismo", "lctools",
"officer", "rvg", "truncnorm", "emdist", "ks", "rlist", "readxl", "OneR", "MASS", "RColorBrewer", "this.path",
"causaloptim", "RBGL", "svglite", "ggrepel", "devtools", "geosphere", "collections")
install_lib = load_lib[!load_lib %in% installed.packages()]
for(lib in install_lib) install.packages(lib, dependencies=TRUE)
sapply(load_lib, require, character=TRUE)
mapStrainToSerovar <- function(){
strain_serovar_map = dict()
strain_serovar_map$set("SAL015", "Enteritidis")$set("SAL019", "Enteritidis")$set("SAL026", "Enteritidis")
strain_serovar_map$set("SAL001", "Typhimurium")$set("SAL010", "Typhimurium")$set("SAL031", "Typhimurium")
strain_serovar_map$set("SAL014", "Newport")$set("SAL016", "Newport")$set("SAL103", "Newport")
strain_serovar_map$set("SAL008", "Heidelberg")$set("SAL017", "Heidelberg")$set("SAL142", "Heidelberg")
strain_serovar_map$set("SAL033", "Montevideo")$set("SAL055", "Montevideo")$set("SAL112", "Montevideo")
strain_serovar_map$set("SAL009", "SaintPaul")$set("SAL028", "SaintPaul")
strain_serovar_map$set("SAL007", "Muenchen")$set("SAL043", "Muenchen")$set("SAL058", "Muenchen")
strain_serovar_map$set("SAL170", "Braenderup")$set("SAL176", "Braenderup")
strain_serovar_map$set("SAL002", "Infantis")$set("SAL060", "Infantis")$set("SAL138", "Infantis")
strain_serovar_map$set("SAL025", "Thompson")$set("SAL030", "Thompson")$set("SAL072", "Thompson")
strain_serovar_map$set("SAL049", "Agona")$set("SAL113", "Agona")$set("SAL144", "Agona")
strain_serovar_map$set("SAL021", "Hadar")$set("SAL125", "Hadar")
strain_serovar_map$set("SAL006", "Anatum")
strain_serovar_map$set("SAL064", "Berta")
strain_serovar_map$set("SAL066", "Brandenburg")
strain_serovar_map$set("SAL003", "Kentucky")
strain_serovar_map$set("SAL053", "B:i:-")
strain_serovar_map$set("SAL050", "Dublin")
strain_serovar_map$set("SAL081", "Manhattan")
strain_serovar_map$set("SAL109", "Mbandaka")
strain_serovar_map$set("SAL078", "Schwartzengrund")
strain_serovar_map$set("SAL065", "Uganda")
return(strain_serovar_map)
}
constructColumnHeader2 <- function(){
col_head = c()
col_head = c(col_head, "TimeStamp")
col_head = c(col_head, "Diameter")
# Haralick Texture - 13 (column 1-13)
for (c in c(1:13)) {
col_head = c(col_head, paste("HT", c, sep = "_"))
}
# PseudoZernike - 230 (column 14-243)
for (c in c(1:230)) {
col_head = c(col_head, paste("PZ", c, sep = "_"))
}
# Max frequency - 256 (column 501-756)
for (c in c(1:256)) {
col_head = c(col_head, paste("MF", c, sep = "_"))
}
# Radial distribution - 362 (column 757-1118)
for (c in c(1:362)) {
col_head = c(col_head, paste("RD", c, sep = "_"))
}
col_head = c(col_head, c("Strain", "Serovar", "SuperClass", "Day"))
return(col_head)
}
mapFeatureName <- function(){
feature_name_map = dict()
feature_name_map$set("HT", "Haralick Texture")
feature_name_map$set("PZ", "PseudoZernike")
feature_name_map$set("SFT", "Spatial Fourier Transform")
feature_name_map$set("MF", "Max Frequency")
feature_name_map$set("RD", "Radial Distribution")
return(feature_name_map)
}
whichSuperClass <- function(serovar){
if(serovar %in% c("Dublin", "Enteritidis", "Newport", "Typhimurium")){
return("DENT")
}else{
return("Non-DENT")
}
}
strain_serovar_map = mapStrainToSerovar()
col_name = constructColumnHeader()
strain_serovar_map = mapStrainToSerovar()
col_name = constructColumnHeader2()
tr_salmonella_features = data.frame()
data_folder_path = "C:/Users/sanja/Documents/GitHub/Salmonella/Data/SAL_TimeLaps_Robot2/"
data_folder_path
strain_file = "SAL_TimeLaps_Robot2.csv"
strain_obv = read.csv(strain_file, header = FALSE)
strain_obv = read.csv(paste(data_folder_path, strain_file, sep=""), header = FALSE)
View(strain_obv)
strain_obv = read.csv(paste(data_folder_path, strain_file, sep=""), header = TRUE)
strain_obv = drop_na(strain_obv)
View(strain_obv)
length(col_name)
day = rep("Day1", length(strain_obv[, 1]))
col_name
length(strain_obv[1,])
strain_obv[, length(strain_obv[1,])]
strain_serovar_map$get(strain_obv[, length(strain_obv[1,])])
i=1
strain_obv[i, length(strain_obv[1,])]
strain_serovar_map$get(strain_obv[i, length(strain_obv[1,])])
serovar = c()
for(i in c(1:length(strain_obv[, 1]))) {
serovar = c(serovar, strain_serovar_map$get(strain_obv[i, length(strain_obv[1,])]) )
}
serovar
col_name
s_class = whichSuperClass(serovar)
serovar = c()
s_class = c()
for(i in c(1:length(strain_obv[, 1]))) {
s = strain_serovar_map$get(strain_obv[i, length(strain_obv[1,])])
serovar = c(serovar,  s)
s_class = c( s_class, whichSuperClass(s))
}
day = rep("Day1", length(strain_obv[, 1]) )
serovar
s_class
strain_obv = cbind(strain_obv, serovar, s_class, day)
View(strain_obv)
colnames(strain_obv) = col_name
write.csv(strain_obv,
file = paste(data_folder_path, "SAL_TimeLaps_Robot2_Combined.csv", sep = ""),
row.names = FALSE)
gc()
#### loading required libraries (there might be more libraries loaded than required)
load_lib = c("deldir", "spatstat", "magrittr", "dplyr", "igraph", "scales", "httr", "tidyverse", "ggnetwork", "ggplot2", "poweRlaw",
"imager", "viridis", "plotrix", "openxlsx", "tidyr", "spdep", "maptools", "tmap", "OpenImageR", "dismo", "lctools",
"officer", "rvg", "truncnorm", "emdist", "ks", "rlist", "readxl", "OneR", "MASS", "RColorBrewer", "this.path",
"causaloptim", "RBGL", "svglite", "ggrepel", "devtools", "geosphere", "collections")
install_lib = load_lib[!load_lib %in% installed.packages()]
for(lib in install_lib) install.packages(lib, dependencies=TRUE)
sapply(load_lib, require, character=TRUE)
mapStrainToSerovar <- function(){
strain_serovar_map = dict()
strain_serovar_map$set("SAL015", "Enteritidis")$set("SAL019", "Enteritidis")$set("SAL026", "Enteritidis")
strain_serovar_map$set("SAL001", "Typhimurium")$set("SAL010", "Typhimurium")$set("SAL031", "Typhimurium")
strain_serovar_map$set("SAL014", "Newport")$set("SAL016", "Newport")$set("SAL103", "Newport")
strain_serovar_map$set("SAL008", "Heidelberg")$set("SAL017", "Heidelberg")$set("SAL142", "Heidelberg")
strain_serovar_map$set("SAL033", "Montevideo")$set("SAL055", "Montevideo")$set("SAL112", "Montevideo")
strain_serovar_map$set("SAL009", "SaintPaul")$set("SAL028", "SaintPaul")
strain_serovar_map$set("SAL007", "Muenchen")$set("SAL043", "Muenchen")$set("SAL058", "Muenchen")
strain_serovar_map$set("SAL170", "Braenderup")$set("SAL176", "Braenderup")
strain_serovar_map$set("SAL002", "Infantis")$set("SAL060", "Infantis")$set("SAL138", "Infantis")
strain_serovar_map$set("SAL025", "Thompson")$set("SAL030", "Thompson")$set("SAL072", "Thompson")
strain_serovar_map$set("SAL049", "Agona")$set("SAL113", "Agona")$set("SAL144", "Agona")
strain_serovar_map$set("SAL021", "Hadar")$set("SAL125", "Hadar")
strain_serovar_map$set("SAL006", "Anatum")
strain_serovar_map$set("SAL064", "Berta")
strain_serovar_map$set("SAL066", "Brandenburg")
strain_serovar_map$set("SAL003", "Kentucky")
strain_serovar_map$set("SAL053", "B:i:-")
strain_serovar_map$set("SAL050", "Dublin")
strain_serovar_map$set("SAL081", "Manhattan")
strain_serovar_map$set("SAL109", "Mbandaka")
strain_serovar_map$set("SAL078", "Schwartzengrund")
strain_serovar_map$set("SAL065", "Uganda")
return(strain_serovar_map)
}
constructColumnHeader2 <- function(){
col_head = c()
col_head = c(col_head, "Observation")
col_head = c(col_head, "Diameter")
# Haralick Texture - 13 (column 1-13)
for (c in c(1:13)) {
col_head = c(col_head, paste("HT", c, sep = "_"))
}
# PseudoZernike - 230 (column 14-243)
for (c in c(1:230)) {
col_head = c(col_head, paste("PZ", c, sep = "_"))
}
# Max frequency - 256 (column 501-756)
for (c in c(1:256)) {
col_head = c(col_head, paste("MF", c, sep = "_"))
}
# Radial distribution - 362 (column 757-1118)
for (c in c(1:362)) {
col_head = c(col_head, paste("RD", c, sep = "_"))
}
col_head = c(col_head, c("TimeStamp", "Strain", "Serovar", "SuperClass", "Day"))
return(col_head)
}
mapFeatureName <- function(){
feature_name_map = dict()
feature_name_map$set("HT", "Haralick Texture")
feature_name_map$set("PZ", "PseudoZernike")
feature_name_map$set("SFT", "Spatial Fourier Transform")
feature_name_map$set("MF", "Max Frequency")
feature_name_map$set("RD", "Radial Distribution")
return(feature_name_map)
}
whichSuperClass <- function(serovar){
if(serovar %in% c("Dublin", "Enteritidis", "Newport", "Typhimurium")){
return("DENT")
}else{
return("Non-DENT")
}
}
mergeTimelapsRobot2Data <- function(){
strain_serovar_map = mapStrainToSerovar()
col_name = constructColumnHeader2()
data_folder_path = "C:/Users/sanja/Documents/GitHub/Salmonella/Data/SAL_TimeLaps_Robot2/"
strain_file = "SAL_TimeLaps_Robot2.csv"
strain_obv = read.csv(paste(data_folder_path, strain_file, sep=""), header = TRUE)
strain_obv = drop_na(strain_obv)
serovar = c()
s_class = c()
for(i in c(1:length(strain_obv[, 1]))) {
s = strain_serovar_map$get(strain_obv[i, length(strain_obv[1,])])
serovar = c(serovar,  s)
s_class = c( s_class, whichSuperClass(s))
}
day = rep("Day1", length(strain_obv[, 1]) )
strain_obv = cbind(strain_obv, serovar, s_class, day)
colnames(strain_obv) = col_name
write.csv(strain_obv,
file = paste(data_folder_path, "SAL_TimeLaps_Robot2_Combined.csv", sep = ""),
row.names = FALSE)
}
#### function call
mergeTimelapsRobot2Data()
